Here is the overview of my CNN playing card detector project so far that I'm making with pytorch:

The root folder for this entire project is 'Card Detection'. Within this, I have a folder 'Card Images' which contains 52 .png images of digital playing cards. Card images are named '2c.png', '3c.png' which corresponds to their truth label (2c = two of clubs). They are colored and are all 27x38 size. These are not 'in real life' photos, so no concern of lighting or orientation, they are always exactly the same.

I have a file 'Detection.ipynb' which contains all the python code for preparing, building, training, and predicting with a CNN model.

End goal: Train a model on the 52 individual card images, so it understand what every card looks like. I want it to overfit, because the test data will be identical to the training data. This is not a typical 'training/validation' machine learning project. The training and testing data look identical, so it's very simple, I'm using it as a foundation. All I need to do is train a model on the card images as they are and over fit as much as possible. This is a unique project where the goal is to overfit as much as possible on the training data.

The problem is the code is scrapped from a different project, so it may need tweaking to simplify or re-work certain aspects. Here's the code done so far, and then I'll post it for you to look at:

1. Imported/installed all the necessary libraries.
2. Prepared the data: Created subclass of pytorch .Dataset. Initialized the class, grabbed the card images and labels, specified the number of classes in the card dataset which is 52, one for each card. Created instances of the subclass we built. The individual cards dataset is the training data. Lastly, made DataLoaders for card data.
3. Built the custom nn.Module CNN model: With 2 conv layers, a maxpool and a fully connected layer.
4. Training the model: on the individual card image training data.
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "%pip install opencv-python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation completed.\n",
      "Number of samples in training dataset: 52\n",
      "Number of samples in testing dataset: 24\n"
     ]
    }
   ],
   "source": [
    "# Preparing the data (Load and manage the images and labels)\n",
    "\n",
    "# Create a dictionary mapping card labels to integers\n",
    "card_to_int = {\n",
    "    'Ah': 0, '2h': 1, '3h': 2, '4h': 3, '5h': 4, '6h': 5, '7h': 6, '8h': 7, '9h': 8, 'Th': 9, 'Jh': 10, 'Qh': 11, 'Kh': 12,\n",
    "    'Ac': 13, '2c': 14, '3c': 15, '4c': 16, '5c': 17, '6c': 18, '7c': 19, '8c': 20, '9c': 21, 'Tc': 22, 'Jc': 23, 'Qc': 24, 'Kc': 25,\n",
    "    'Ad': 26, '2d': 27, '3d': 28, '4d': 29, '5d': 30, '6d': 31, '7d': 32, '8d': 33, '9d': 34, 'Td': 35, 'Jd': 36, 'Qd': 37, 'Kd': 38,\n",
    "    'As': 39, '2s': 40, '3s': 41, '4s': 42, '5s': 43, '6s': 44, '7s': 45, '8s': 46, '9s': 47, 'Ts': 48, 'Js': 49, 'Qs': 50, 'Ks': 51\n",
    "}\n",
    "\n",
    "# Create subclass of the pytorch base custom dataset.\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # Initializes the parameters and loads in the native data.\n",
    "    def __init__(self, root_dir, transform=None, is_table=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_table = is_table\n",
    "        \n",
    "        # If the dataset is the table screenshots:\n",
    "        if self.is_table:\n",
    "            # Opens the .json and loads the table labels, saves info required to load images later, and stores this to 'self.table_info'.\n",
    "            with open('C:/Users/Admin/Desktop/Primary Skills/Programming & ML/Machine Learning/Card Detection/Tables.json', 'r') as f:\n",
    "                self.table_info = json.load(f)\n",
    "        # Otherwise the dataset is the card images. Lists all the files in 'Card Images' and stores them to 'self.card_info'.\n",
    "        else:\n",
    "            self.card_info = os.listdir(os.path.join(root_dir, 'C:/Users/Admin/Desktop/Primary Skills/Programming & ML/Machine Learning/Card Detection/Card Images'))\n",
    "\n",
    "    # Gets total number of samples, used to determine the number of iterations required to go through entire dataset.\n",
    "    def __len__(self):\n",
    "        if self.is_table:\n",
    "            return len(self.table_info)\n",
    "        else:\n",
    "            return len(self.card_info)\n",
    "\n",
    "    # Load and return a sample from the dataset given an index. When using data loaders, this is called to fetch a specific sample from the dataset.\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.is_table:\n",
    "            # Retrieves the tables image path and associated label for the table image.\n",
    "            img_path = os.path.join(self.root_dir, self.table_info[idx]['table_image'])\n",
    "            label = self.table_info[idx]['table_label']\n",
    "        else:\n",
    "            # Retrieves the card image name and path and then extracts the truth label as the images name before '.png'.\n",
    "            img_name = self.card_info[idx]\n",
    "            img_path = os.path.join('C:/Users/Admin/Desktop/Primary Skills/Programming & ML/Machine Learning/Card Detection/Card Images', img_name)\n",
    "            card_label = img_name[:-4]\n",
    "            label = card_to_int[card_label]\n",
    "        \n",
    "        # Opens the image via the card and table image paths.\n",
    "        img = Image.open(img_path)\n",
    "        # Converts images to RGB that were currently RGB with Alpha (RGBA).\n",
    "        img = img.convert(\"RGB\")\n",
    "\n",
    "        # Applies the transformations to the images when they are accessed through the dataset instances. \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "# Number of classes in the card dataset (52 cards).\n",
    "num_classes = 52\n",
    "# (channels, [dimensions of image in pixels]). RGB = 3.\n",
    "input_shape = (3, 27, 38)\n",
    "\n",
    "# Transforms the images shape to account for different sized cards and various table screenshot dimensions, and converts image into tensor.\n",
    "cards_transform = transforms.Compose([transforms.RandomResizedCrop(27, scale=(0.6, 2.0)),transforms.ToTensor()])\n",
    "table_transform = transforms.Compose([transforms.Resize(505, Image.BICUBIC),transforms.ToTensor()])\n",
    "\n",
    "# ImageDataset instances.\n",
    "root_dir = \"C:\\\\Users\\\\Admin\\\\Desktop\\\\Primary Skills\\\\Programming & ML\\\\Machine Learning\\\\Card Detection\"\n",
    "cards_dataset = ImageDataset(root_dir=root_dir, transform=cards_transform)\n",
    "table_dataset = ImageDataset(root_dir=root_dir, transform=table_transform, is_table=True)\n",
    "\n",
    "# Use the cards_dataset as the training set and table_dataset as the validation set.\n",
    "train_dataset = cards_dataset\n",
    "test_dataset = table_dataset\n",
    "\n",
    "# Objects to provide access to the tensor data during training and testing.\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(\"Data preparation completed.\")\n",
    "print(f\"Number of samples in training dataset: {len(train_dataset)}\")\n",
    "print(f\"Number of samples in testing dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CardCNN(\n",
      "  (conv1): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=200, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=52, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Building the model (Creating custom CNN 'CNN' using nn.Module class)\n",
    "class CardCNN(nn.Module):\n",
    "    # Initialization function\n",
    "    def __init__(self):\n",
    "        # Constructor which initializes the layers and defines parameters.\n",
    "        super(CardCNN, self).__init__()\n",
    "        # convolutional layer for extracting local features/patterns. (input channels, output channels, kernel size, stride).\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3, 1)\n",
    "        # max pooling layer for downsampling to retain important features & reduce spatial dimensions. (kernel size, stride).\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # convolutional layer for extracting local features/patterns. (input channels, output channels, kernel size, stride).\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, 1)\n",
    "        # dropout layer for regularization. Prevents overfitting. (Probability of element dropped during dropout).\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # fully connected layer which flattens for classification. (input size, output size).\n",
    "        self.fc1 = nn.Linear(8 * 5 * 5, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    # Function to define how the input flows through the layers.\n",
    "    def forward(self, x):\n",
    "        # Applies convolutional layer, activation function (ReLU) for non-linearity, and pooling layer to the input.\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Reshapes the output tensor to match the input size of the fully connected layer.\n",
    "        x = x.view(-1, 8 * 5 * 5)\n",
    "        # Applies dropout layer to prevent overfitting by randomly zeroing some elements.\n",
    "        x = self.dropout(x)\n",
    "        # # Applies ReLU activation function to the output of the first fully connected layer.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Applies dropout layer to the output of the first fully connected layer.\n",
    "        x = self.dropout(x)\n",
    "        # Flattens and passes the input through the fully connected layer, performs linear transformation for classification.\n",
    "        x = self.fc2(x)\n",
    "        # Logarithmic softmax function applied to produce the output probabilities.\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = CardCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the individual cards\n",
    "\n",
    "# Device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer using Stochastic Gradient Descent (SGD) algo during training with the set learning rate and momentum\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "# Loss function (combines softmax activation and negative log-likelihood loss).\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 200\n",
    "# Loop through the number of epochs.\n",
    "for epoch in range(num_epochs):\n",
    "    # Initialize the running loss.\n",
    "    running_loss = 0.0\n",
    "    #iterate over the DataLoader (train_loader) to get batches of input images and their labels.\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        # Move the inputs and labels to the appropriate device (CPU or GPU).\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Clear the gradients of the model parameters before each forward pass.\n",
    "        optimizer.zero_grad()\n",
    "        # Pass the input images through the model to get the predicted outputs.\n",
    "        outputs = model(inputs)\n",
    "        # Calculate the loss between the predicted outputs and the ground truth labels.\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Perform backpropagation to compute gradients of the loss with respect to the model parameters.\n",
    "        loss.backward()\n",
    "        # Update the model parameters using the optimizer.\n",
    "        optimizer.step()\n",
    "        # Accumulate the running loss for each batch.\n",
    "        running_loss += loss.item()\n",
    "    # At the end of each epoch, print the average loss for that epoch.\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / (i + 1)}\")\n",
    "\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate sliding window coordinates\n",
    "def sliding_window(image, window_size, step_size):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step_size):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step_size):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n",
    "\n",
    "# Function to predict card class probabilities for a single input image\n",
    "def predict_single_image(model, image):\n",
    "    with torch.no_grad():\n",
    "        image_tensor = torch.unsqueeze(image, 0)\n",
    "        output = model(image_tensor)\n",
    "        return output\n",
    "\n",
    "# Parameters for the sliding window\n",
    "window_size = (27, 38)\n",
    "step_size = 10\n",
    "\n",
    "# Iterate over the table images\n",
    "for idx, (table_image, _) in enumerate(test_dataset):\n",
    "    # Convert PIL Image to a numpy array and normalize it to [0, 1]\n",
    "    table_image_np = np.array(table_image).transpose(1, 2, 0) / 255.0\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over the sliding windows\n",
    "    for (x, y, window) in sliding_window(table_image_np, window_size, step_size):\n",
    "        # Convert the numpy window back to a PIL Image and apply the cards_transform\n",
    "        window_pil = Image.fromarray((window * 255).astype(np.uint8))\n",
    "        window_transformed = cards_transform(window_pil)\n",
    "\n",
    "        # Predict card class probabilities and store the predictions with their window coordinates\n",
    "        window_probs = predict_single_image(model, window_transformed)\n",
    "        predictions.append(((x, y), window_probs))\n",
    "\n",
    "    # Analyze the predictions to find the most probable card locations\n",
    "    # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the trained model (OLD MNIST PROJECT)\n",
    "def test(model, device, test_loader):\n",
    "    # Sets model in evaluation mode (disables dropout and batch normalization).\n",
    "    model.eval()\n",
    "    # Initialization of cumulative loss and correctly predicted samples.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Iterates over (image, label) batches in test dataset.\n",
    "    for data, target in test_loader:\n",
    "        # Input data and target labels moved to the GPU/CPU.\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # forward pass is performed, obtaining predicted outputs.\n",
    "        output = model(data)\n",
    "        # Accumulated test loss between predicted output and target labels.\n",
    "        test_loss += criterion(output, target).item()\n",
    "        # Tensor containing the predicted labels by taking the idx of the max value .\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        # Accumulated correct predictions by comparing predicted labels with target labels.\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    # Obtains average loss.\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # Average loss and accuracy are printed.\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "# Runs training process for n-1 epochs.\n",
    "for epoch in range(1, 6):\n",
    "    # Train function called to train the model on training dataset.\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    # Test function called to evaluate models performance on test dataset.\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset \n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data (Load and manage the images and labels)\n",
    "\n",
    "# Create subclass of the pytorch base custom dataset.\n",
    "class CardDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    # Initializes the parameters and loads in the native data.\n",
    "    def __init__(self, root_dir, transform=None, is_table=False):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.is_table = is_table\n",
    "        \n",
    "        # If the dataset is the table screenshots:\n",
    "        if self.is_table:\n",
    "            # Opens the .json and loads the table labels, saves info required to load images later, and stores this to 'self.table_info'.\n",
    "            with open(os.path.join(root_dir, '..\\Tables.json'), 'r') as f:\n",
    "                self.table_info = json.load(f)\n",
    "        # Otherwise the dataset is the card images. Lists all the files in 'Card Images' and stores them to 'self.card_info'.\n",
    "        else:\n",
    "            self.card_info = os.listdir(os.path.join(root_dir, '..\\Card Images'))\n",
    "\n",
    "    # Gets total number of samples, used to determine the number of iterations required to go through entire dataset.\n",
    "    def __len__(self):\n",
    "        if self.is_table:\n",
    "            return len(self.table_info)\n",
    "        else:\n",
    "            return len(self.card_info)\n",
    "\n",
    "    # Load and return a sample from the dataset given an index. When using data loaders, this is called to fetch a specific sample from the dataset.\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.is_table:\n",
    "            # Retrieves the tables image path and associated label for the table image.\n",
    "            img_path = os.path.join(self.root_dir, self.table_info[idx]['table_image'])\n",
    "            label = self.table_info[idx]['table_label']\n",
    "        else:\n",
    "            # Retrieves the card image name and path and then extracts the truth label as the images name before '.png'.\n",
    "            img_name = self.card_info[idx]\n",
    "            img_path = os.path.join(self.root_dir, img_name)\n",
    "            label = img_name[:-4]\n",
    "\n",
    "        # Opens the image via the card and table image paths.\n",
    "        img = Image.open(img_path)\n",
    "        # Applies the transformations to the images when they are accessed through the dataset instances. \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "# Number of classes in the card dataset (52 cards).\n",
    "num_classes = 52\n",
    "# (channels, [dimensions of image in pixels]). RGB = 3.\n",
    "input_shape = (3, 27, 38)\n",
    "\n",
    "# Transforms the images shape to account for different sized cards and various table screenshot dimensions, and converts image into tensor.\n",
    "cards_transform = transforms.Compose([transforms.RandomResizedCrop(27, scale=(0.6, 2.0)),transforms.ToTensor()])\n",
    "table_transform = transforms.Compose([transforms.Resize(505, Image.BICUBIC),transforms.ToTensor()])\n",
    "\n",
    "# CardDataset instances.\n",
    "root_dir = os.path.abspath('Card Detection')\n",
    "cards_dataset = CardDataset(root_dir=root_dir, transform=cards_transform)\n",
    "table_dataset = CardDataset(root_dir=root_dir, transform=table_transform, is_table=True)\n",
    "\n",
    "# Use the cards_dataset as the training set and table_dataset as the validation set.\n",
    "train_dataset = cards_dataset\n",
    "test_dataset = table_dataset\n",
    "\n",
    "# Objects to provide access to the tensor data during training and testing.\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model (Creating custom CNN 'CNN' using nn.Module class)\n",
    "class CardCNN(nn.Module):\n",
    "    # Initialization function\n",
    "    def __init__(self):\n",
    "        # Constructor which initializes the layers and defines parameters.\n",
    "        super(CardCNN, self).__init__()\n",
    "        # convolutional layer for extracting local features/patterns. (input channels, output channels, kernel size, stride).\n",
    "        self.conv1 = nn.Conv2d(3, 4, 3, 1)\n",
    "        # max pooling layer for downsampling to retain important features & reduce spatial dimensions. (kernel size, stride).\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # convolutional layer for extracting local features/patterns. (input channels, output channels, kernel size, stride).\n",
    "        self.conv2 = nn.Conv2d(4, 8, 3, 1)\n",
    "        # dropout layer for regularization. Prevents overfitting. (Probability of element dropped during dropout).\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        # fully connected layer which flattens for classification. (input size, output size).\n",
    "        self.fc1 = nn.Linear(8 * 5 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    # Function to define how the input flows through the layers.\n",
    "    def forward(self, x):\n",
    "        # Applies convolutional layer, activation function (ReLU) for non-linearity, and pooling layer to the input.\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # Reshapes the output tensor to match the input size of the fully connected layer.\n",
    "        x = x.view(-1, 8 * 5 * 8)\n",
    "        # Applies dropout layer to prevent overfitting by randomly zeroing some elements.\n",
    "        x = self.dropout(x)\n",
    "        # ???\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # ???\n",
    "        x = self.dropout(x)\n",
    "        # Flattens and passes the input through the fully connected layer, performs linear transformation for classification.\n",
    "        x = self.fc2(x)\n",
    "        # Logarithmic softmax function applied to produce the output probabilities.\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = CardCNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "# Device selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer using Adam op algo to optimize parameters during training with the set learning rate.\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Loss function (combines softmax activation and negative log-likelihood loss).\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Performs the training loop for a number of epochs.\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Sets model in training mode, so it can update it's parameters during training.\n",
    "    model.train()\n",
    "    # Iterates over the loader.\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Input data and target labels moved to the GPU/CPU.\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Optimizer's gradients reset to clear accumulated gradients from pervious batches.\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass is performed, obtaining predicted outputs.\n",
    "        output = model(data)\n",
    "        # Loss calculated by comparing predicted outputs with target labels.\n",
    "        loss = criterion(output, target)\n",
    "        # Gradients are computed and backproped.\n",
    "        loss.backward()\n",
    "        # Optimizer updates models parameters.\n",
    "        optimizer.step()\n",
    "        # Prints current training process when we hit a round number. Loss.item() is scalar value of the loss tensor.\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the trained model\n",
    "def test(model, device, test_loader):\n",
    "    # Sets model in evaluation mode (disables dropout and batch normalization).\n",
    "    model.eval()\n",
    "    # Initialization of cumulative loss and correctly predicted samples.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Ensures no gradient calcs are performed during the evaluation, reducing memory consumption.\n",
    "    with torch.no_grad():\n",
    "        # Iterates over (image, label) batches in test dataset.\n",
    "        for data, target in test_loader:\n",
    "            # Input data and target labels moved to the GPU/CPU.\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # forward pass is performed, obtaining predicted outputs.\n",
    "            output = model(data)\n",
    "            # Accumulated test loss between predicted output and target labels.\n",
    "            test_loss += criterion(output, target).item()\n",
    "            # Tensor containing the predicted labels by taking the idx of the max value .\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Accumulated correct predictions by comparing predicted labels with target labels.\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    # Obtains average loss.\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # Average loss and accuracy are printed.\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
    "# Runs training process for n-1 epochs.\n",
    "for epoch in range(1, 6):\n",
    "    # Train function called to train the model on training dataset.\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    # Test function called to evaluate models performance on test dataset.\n",
    "    test(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
